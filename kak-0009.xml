<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="default.xsl"?>
<fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="true"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>1407</fr:anchor><fr:addr
type="user">kak-0009</fr:addr><fr:route>kak-0009.xml</fr:route><fr:title
text="Contrastive Learning">Contrastive Learning</fr:title><fr:date><fr:year>2024</fr:year><fr:month>10</fr:month><fr:day>31</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter><fr:p>Prior to understanding contrastive reinforcement learning, it is important to have an at least rudimentary understanding of contrastive learning. Historically, contrastive learning has been used to learn representations. The fundamental idea behind contrastive learning is to encourage the representations of similar outputs to be similar in representation space.</fr:p><fr:p><fr:strong>Supervised setting:</fr:strong> For now, assume we are in the supervised setting (we have access to lables). Suppose that we are learning a representation in <fr:tex
display="inline"><![CDATA[\mathbb {R}^d]]></fr:tex>. Our model is a classifier on dogs and cats. If we have two dogs <fr:tex
display="inline"><![CDATA[y_1]]></fr:tex> and <fr:tex
display="inline"><![CDATA[y_2]]></fr:tex> then we want the learned representation map <fr:tex
display="block"><![CDATA[\phi : \{\text {dogs}, \text {cats}\} \to  \mathbb {R}^d]]></fr:tex> to be such that <fr:tex
display="inline"><![CDATA[\phi (y_1)]]></fr:tex> and <fr:tex
display="inline"><![CDATA[\phi (y_2)]]></fr:tex> are "close" in <fr:tex
display="inline"><![CDATA[\mathbb {R}^d]]></fr:tex>. Now the notion of "close" is to be determined by the user. An example could be to minimize the inner product between their representation maps i.e. we could learn a feature map parametrized by <fr:tex
display="inline"><![CDATA[\theta ]]></fr:tex> with the following objective <fr:tex
display="block"><![CDATA[\max _{\theta }\ \langle  \phi _{\theta }(y_1), \phi _{\theta }(y_2) \rangle .]]></fr:tex> Similarly, we want dissimilar outputs to be far apart in representation space. If <fr:tex
display="inline"><![CDATA[y_3]]></fr:tex> is a cat, then we can introduce a regularization to encourage this i.e.
<fr:tex
display="block"><![CDATA[\max _{\theta }\ \langle  \phi _{\theta }(y_1), \phi _{\theta }(y_2) \rangle  - \sum _{i \in  \{1, 2\}} \langle  \phi _{\theta }(y_i), \phi _{\theta }(y_3) \rangle .]]></fr:tex> The astute reader will (correctly) ask why we would do this over supervised learning? The answer is we wouldn't. This is just an illustrative example. The real power of contrastive learning comes from being able to utilize un-labeled samples.</fr:p><fr:p><fr:strong>Unsupervised setting:</fr:strong> Now suppose that we get rid of labels and are just given <fr:tex
display="inline"><![CDATA[n]]></fr:tex> dog samples <fr:tex
display="inline"><![CDATA[\mathcal {D}]]></fr:tex> from some distribution <fr:tex
display="inline"><![CDATA[p_{\mathcal {D}}]]></fr:tex>. We now want to be able to learn <fr:tex
display="inline"><![CDATA[p_{\theta }]]></fr:tex> to somehow estimate this distribution. An approach is to learn to distinguish the sample dogs given from random noise. To do so, we generate <fr:tex
display="inline"><![CDATA[n]]></fr:tex> random images <fr:tex
display="inline"><![CDATA[\mathcal {R}]]></fr:tex> according to some distribution <fr:tex
display="inline"><![CDATA[p_{\mathcal {R}}]]></fr:tex>. We can now return to the supervised learning setting, where we treat <fr:tex
display="inline"><![CDATA[\mathcal {D}]]></fr:tex> and <fr:tex
display="inline"><![CDATA[\mathcal {R}]]></fr:tex> as two classes. If we recall standard supervised learning practice, given a sample <fr:tex
display="inline"><![CDATA[x]]></fr:tex>, we then want to find <fr:tex
display="block"><![CDATA[p(\mathcal {D} \mid  x) = 1 - p(\mathcal {R} \mid  X).]]></fr:tex> 
As an explicit example, we will use logistic regression. Namely, we will model <fr:tex
display="inline"><![CDATA[p(x) = p(\mathcal {D} \mid  x)]]></fr:tex> as <fr:tex
display="block"><![CDATA[p_{\theta }(x) = \frac {1}{1 + e^{-G_{\theta }(x)}}.]]></fr:tex> However, <fr:tex
display="inline"><![CDATA[p_{\theta }(x)]]></fr:tex> is estimating <fr:tex
display="inline"><![CDATA[p(\mathcal {D} \mid  x)]]></fr:tex>, where we care about <fr:tex
display="inline"><![CDATA[p(x \mid  \mathcal {D})]]></fr:tex>. To estimate the correct quantity, we need to leverage our knowledge of the noise distribution. Recall that if <fr:tex
display="inline"><![CDATA[p_{\theta }(x) = p(\mathcal {D} \mid  x)]]></fr:tex> then <fr:tex
display="inline"><![CDATA[G_{\theta }(x) = \log  \frac {p(x \mid  \mathcal {D})}{p(x \mid  \mathcal {R})}]]></fr:tex>. Since we generated the samples from <fr:tex
display="inline"><![CDATA[\mathcal {R}]]></fr:tex>, we have the explicit distribution i.e. <fr:tex
display="inline"><![CDATA[p(x \mid  \mathcal {R}) = p_{\mathcal {R}}(x)]]></fr:tex>. Therefore, we can restrict <fr:tex
display="inline"><![CDATA[G_{\theta }]]></fr:tex> to explicitly learn <fr:tex
display="inline"><![CDATA[p(x \mid  \mathcal {D})]]></fr:tex> by considering <fr:tex
display="block"><![CDATA[G_{\theta }(x) = \log  p_{\theta }(x \mid  \mathcal {D}) - \log  p_{\mathcal {R}}(x),]]></fr:tex> considering the cross entropy loss we get the <fr:link
type="external"
href="nce">NCE loss</fr:link></fr:p><fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>534</fr:anchor><fr:addr
type="user">kak-000E</fr:addr><fr:route>kak-000E.xml</fr:route><fr:title
text="NCE loss">NCE loss</fr:title><fr:taxon>Definition</fr:taxon><fr:date><fr:year>2024</fr:year><fr:month>11</fr:month><fr:day>4</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter><fr:p>The <fr:em><fr:link
type="external"
href="nce">NCE</fr:link></fr:em> loss aims to minimize the following objective <fr:tex
display="block"><![CDATA[\mathcal {L}_{N} = - \sum _{t} \log  \left [h(x_t; \theta )\right ] + \log \left [1 - h(y_t; \theta )\right ],]]></fr:tex> where <fr:tex
display="inline"><![CDATA[x_t]]></fr:tex> are samples from the data distribution and <fr:tex
display="inline"><![CDATA[y_t]]></fr:tex> are randomly generated samples and <fr:tex
display="block"><![CDATA[\begin {array}{r c l}{{h({\bf  u};\theta )}}&{{=}}&{{\frac {1}{1+\exp \left [-G({\bf  u};\theta )\right ]},}}\\ {{G({\bf  u};\theta )}}&{{=}}&{{\ln  p_{m}({\bf  u};\theta )-\ln  p_{n}({\bf  u}).}}\end {array}]]></fr:tex></fr:p></fr:mainmatter><fr:backmatter /></fr:tree><fr:p>In <fr:link
type="local"
href="gutmann2012.xml"
addr="gutmann2012"
title="Noise-contrastive Estimation">Noise-contrastive Estimation</fr:link>, they show under mild conditions that the estimator <fr:tex
display="inline"><![CDATA[p_{\theta }(x \mid  D) \to  p_{\mathcal {D}}(x)]]></fr:tex> in probability as the number of samples in the loss goes to infinity. Equivalently, the estimator is <fr:link
type="local"
href="kak-000F.xml"
addr="kak-000F"
title="Consistent estimator">consistent</fr:link>.</fr:p><fr:p><fr:strong>Time series:</fr:strong> Before we get to contrastive RL, it is a natural question to wonder how does this apply to temporal sequences? Concretely, we want to make predictions about the future given the current "context". However, we want to do so in an unsupervised way, meaning we are only given trajectories not a notion of what it means for a trajectory to be good. Naively, one can try to do this in a supervised manner. For a <fr:tex
display="inline"><![CDATA[k]]></fr:tex> step prediction, this would just be your model predicting what will happen in <fr:tex
display="inline"><![CDATA[k]]></fr:tex> steps then seeing if it matches what occured <fr:tex
display="inline"><![CDATA[k]]></fr:tex> steps in the future in the sample trajectory. However, if your sample space <fr:tex
display="inline"><![CDATA[\mathcal {X}]]></fr:tex> is very high-dimensional, modeling this relationship can require an exorbinant amount of trajectories.</fr:p><fr:p>Fast forwarding to contrastive RL, current work is primarily considered with a particular contrastive objective.</fr:p><fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>535</fr:anchor><fr:addr
type="user">kak-000B</fr:addr><fr:route>kak-000B.xml</fr:route><fr:title
text="InfoNCE">InfoNCE</fr:title><fr:taxon>Definition</fr:taxon><fr:date><fr:year>2024</fr:year><fr:month>11</fr:month><fr:day>4</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter><fr:p>The <fr:em><fr:link
type="local"
href="vandenOord2018.xml"
addr="vandenOord2018"
title="Contrastive Predictive Decoding">InfoNCE</fr:link></fr:em> loss aims to minimize the following information-theoretic objective <fr:tex
display="block"><![CDATA[\mathcal {L}_{N} = - \mathbb {E}_{\mathcal {X}} \left [\log  \frac {f_k(x_{t + k}, c_t)}{\sum _{x_j \in  \mathcal {X}} f_k(x_j, c_t)}\right ]]]></fr:tex></fr:p></fr:mainmatter><fr:backmatter /></fr:tree><fr:p>Now we need to unpack this very ominous loss. To start, what are <fr:tex
display="inline"><![CDATA[x_k]]></fr:tex> and <fr:tex
display="inline"><![CDATA[c_t]]></fr:tex>?</fr:p><fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>536</fr:anchor><fr:addr
type="user">kak-000C</fr:addr><fr:route>kak-000C.xml</fr:route><fr:title
text="Maximize Mutual info">Maximize Mutual info</fr:title><fr:taxon>Theorem</fr:taxon><fr:date><fr:year>2024</fr:year><fr:month>11</fr:month><fr:day>4</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter><fr:p><fr:tex
display="inline"><![CDATA[\mathcal {L}_N]]></fr:tex> from <fr:link
type="local"
href="vandenOord2018.xml"
addr="vandenOord2018"
title="Contrastive Predictive Decoding">Contrastive Predictive Decoding</fr:link> maximizes a lower bound on the <fr:link
type="local"
href="kak-000V.xml"
addr="kak-000V"
title="Mutual Information">Mutual Information</fr:link> between <fr:tex
display="inline"><![CDATA[x_{t + k}]]></fr:tex> and <fr:tex
display="inline"><![CDATA[c_t]]></fr:tex>.</fr:p>
   
   <fr:tree
toc="false"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>537</fr:anchor><fr:addr
type="machine">#316</fr:addr><fr:route>unstable-316.xml</fr:route><fr:taxon>Proof</fr:taxon><fr:date><fr:year>2024</fr:year><fr:month>11</fr:month><fr:day>4</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter>All we must do is plug <fr:tex
display="inline"><![CDATA[\frac {p(x \mid  c)}{p(x)}]]></fr:tex> back into the objective.
  <fr:tex
display="block"><![CDATA[\begin {align*}     \mathcal {L}_{\mathbb {N}}^{\text {opt}}&=-\,\mathbb {E}\log \left [\frac {\frac {p(x_{t+k}|c_{t})}{p(x_{t+k})}}{\frac {p(x_{t+k}|c_{t})}{p(x_{t+k})}+\sum _{x_{j}\in  X_{\text {neg}}}\frac {p(x_{j}|c_{t})}{p(x_{j})}}\right ] \\     &=\mathbb {E}\log \left [1+\frac {p(x_{t+k})}{p(x_{t+k}|c_{t})}\sum _{x_{j}\in  X_{\text {neg}}}\frac {p(x_{j}|c_{t})}{p(x_{j})}\right ] \\     &\approx \mathbb {E}\log \left [1+\frac {p(x_{t+k})}{p(x_{t+k}|c_{t})}(N-1)\,\mathbb {E}\,\frac {p(x_{j}|c_{t})}{p(x_{j})}\right ] \\     &=\mathbb {E}\log \left [1+\frac {p(x_{t+k})}{p(x_{t+k} \mid  c_t)}N\right ] \\     &\geq  \mathbb {E} \log  \left [\frac {p(x_{t + k})}{p(x_{t + k} \mid  c_t)}N \right ] \\     &= - I(x_{t + k}, c_t) + \log  N  \end {align*}   ]]></fr:tex>
</fr:mainmatter><fr:backmatter /></fr:tree>
 

</fr:mainmatter><fr:backmatter /></fr:tree></fr:mainmatter><fr:backmatter><fr:tree
toc="false"
numbered="false"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:title
text="References">References</fr:title><fr:authors /></fr:frontmatter><fr:mainmatter><fr:tree
toc="true"
numbered="false"
show-heading="true"
show-metadata="true"
expanded="false"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>1408</fr:anchor><fr:addr
type="user">vandenOord2018</fr:addr><fr:route>vandenOord2018.xml</fr:route><fr:title
text="Contrastive Predictive Decoding">Contrastive Predictive Decoding</fr:title><fr:taxon>Reference</fr:taxon><fr:authors /><fr:meta
name="doi">10.48550/arXiv.1807.03748</fr:meta><fr:meta
name="bibtex"><![CDATA[@misc{oord2019representationlearningcontrastivepredictive,
      title={Representation Learning with Contrastive Predictive Coding}, 
      author={Aaron van den Oord and Yazhe Li and Oriol Vinyals},
      year={2019},
      eprint={1807.03748},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1807.03748}, 
}]]></fr:meta></fr:frontmatter><fr:mainmatter /><fr:backmatter /></fr:tree><fr:tree
toc="true"
numbered="false"
show-heading="true"
show-metadata="true"
expanded="false"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>1409</fr:anchor><fr:addr
type="user">gutmann2012</fr:addr><fr:route>gutmann2012.xml</fr:route><fr:title
text="Noise-contrastive Estimation">Noise-contrastive Estimation</fr:title><fr:taxon>Reference</fr:taxon><fr:authors /><fr:meta
name="abstract">We present a new estimation principle for parameterized statistical models. The idea is to perform nonlinear logistic regression to discriminate between the observed data and some artificially generated noise, using the model log-density function in the regression nonlinearity.  We show that this leads to a consistent (convergent) estimator of the parameters, and analyze the asymptotic variance.  In particular, the method is shown to directly work for unnormalized models, i.e. models where the density function does not integrate to one. The normalization constant can be estimated just like any other parameter. For a tractable ICA model, we compare the method with other estimation methods that can be used to learn unnormalized models, including score matching, contrastive divergence, and maximum-likelihood where the normalization constant is estimated with importance sampling. Simulations show that noise-contrastive estimation offers the best trade-off between computational and statistical efficiency. The method is then applied to the modeling of natural images: We show that the method can successfully estimate a large-scale two-layer model and a Markov random field.</fr:meta><fr:meta
name="bibtex"><![CDATA[@InProceedings{pmlr-v9-gutmann10a,
  title = 	 {Noise-contrastive estimation: A new estimation principle for unnormalized statistical models},
  author = 	 {Gutmann, Michael and Hyvärinen, Aapo},
  booktitle = 	 {Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics},
  pages = 	 {297--304},
  year = 	 {2010},
  editor = 	 {Teh, Yee Whye and Titterington, Mike},
  volume = 	 {9},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Chia Laguna Resort, Sardinia, Italy},
  month = 	 {13--15 May},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v9/gutmann10a/gutmann10a.pdf},
  url = 	 {https://proceedings.mlr.press/v9/gutmann10a.html},
}]]></fr:meta></fr:frontmatter><fr:mainmatter /><fr:backmatter /></fr:tree></fr:mainmatter><fr:backmatter /></fr:tree><fr:tree
toc="false"
numbered="false"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:title
text="Context">Context</fr:title><fr:authors /></fr:frontmatter><fr:mainmatter><fr:tree
toc="true"
numbered="false"
show-heading="true"
show-metadata="true"
expanded="false"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>1410</fr:anchor><fr:addr
type="user">kak-0005</fr:addr><fr:route>kak-0005.xml</fr:route><fr:title
text="Contrastive Reinforcement Learning">Contrastive Reinforcement Learning</fr:title><fr:date><fr:year>2024</fr:year><fr:month>10</fr:month><fr:day>29</fr:day></fr:date><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter><fr:p>In this blog post, we aim to demistify <fr:link
type="external"
href="gcrl"><fr:em>Contrastive Reinforcement Learning</fr:em></fr:link>. This term often gets thrown around in the dark inner circles of the reinforcement learning community. However, for those that are not familiar with contrastive learning, what does contrastive even mean? For those that are, how can reinforcement learning be contrastive? Throughout this blog post, we will answer these questions and many more.</fr:p><fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>533</fr:anchor><fr:addr
type="user">kak-0009</fr:addr><fr:route>kak-0009.xml</fr:route><fr:title
text="Contrastive Learning">Contrastive Learning</fr:title><fr:date><fr:year>2024</fr:year><fr:month>10</fr:month><fr:day>31</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter><fr:p>Prior to understanding contrastive reinforcement learning, it is important to have an at least rudimentary understanding of contrastive learning. Historically, contrastive learning has been used to learn representations. The fundamental idea behind contrastive learning is to encourage the representations of similar outputs to be similar in representation space.</fr:p><fr:p><fr:strong>Supervised setting:</fr:strong> For now, assume we are in the supervised setting (we have access to lables). Suppose that we are learning a representation in <fr:tex
display="inline"><![CDATA[\mathbb {R}^d]]></fr:tex>. Our model is a classifier on dogs and cats. If we have two dogs <fr:tex
display="inline"><![CDATA[y_1]]></fr:tex> and <fr:tex
display="inline"><![CDATA[y_2]]></fr:tex> then we want the learned representation map <fr:tex
display="block"><![CDATA[\phi : \{\text {dogs}, \text {cats}\} \to  \mathbb {R}^d]]></fr:tex> to be such that <fr:tex
display="inline"><![CDATA[\phi (y_1)]]></fr:tex> and <fr:tex
display="inline"><![CDATA[\phi (y_2)]]></fr:tex> are "close" in <fr:tex
display="inline"><![CDATA[\mathbb {R}^d]]></fr:tex>. Now the notion of "close" is to be determined by the user. An example could be to minimize the inner product between their representation maps i.e. we could learn a feature map parametrized by <fr:tex
display="inline"><![CDATA[\theta ]]></fr:tex> with the following objective <fr:tex
display="block"><![CDATA[\max _{\theta }\ \langle  \phi _{\theta }(y_1), \phi _{\theta }(y_2) \rangle .]]></fr:tex> Similarly, we want dissimilar outputs to be far apart in representation space. If <fr:tex
display="inline"><![CDATA[y_3]]></fr:tex> is a cat, then we can introduce a regularization to encourage this i.e.
<fr:tex
display="block"><![CDATA[\max _{\theta }\ \langle  \phi _{\theta }(y_1), \phi _{\theta }(y_2) \rangle  - \sum _{i \in  \{1, 2\}} \langle  \phi _{\theta }(y_i), \phi _{\theta }(y_3) \rangle .]]></fr:tex> The astute reader will (correctly) ask why we would do this over supervised learning? The answer is we wouldn't. This is just an illustrative example. The real power of contrastive learning comes from being able to utilize un-labeled samples.</fr:p><fr:p><fr:strong>Unsupervised setting:</fr:strong> Now suppose that we get rid of labels and are just given <fr:tex
display="inline"><![CDATA[n]]></fr:tex> dog samples <fr:tex
display="inline"><![CDATA[\mathcal {D}]]></fr:tex> from some distribution <fr:tex
display="inline"><![CDATA[p_{\mathcal {D}}]]></fr:tex>. We now want to be able to learn <fr:tex
display="inline"><![CDATA[p_{\theta }]]></fr:tex> to somehow estimate this distribution. An approach is to learn to distinguish the sample dogs given from random noise. To do so, we generate <fr:tex
display="inline"><![CDATA[n]]></fr:tex> random images <fr:tex
display="inline"><![CDATA[\mathcal {R}]]></fr:tex> according to some distribution <fr:tex
display="inline"><![CDATA[p_{\mathcal {R}}]]></fr:tex>. We can now return to the supervised learning setting, where we treat <fr:tex
display="inline"><![CDATA[\mathcal {D}]]></fr:tex> and <fr:tex
display="inline"><![CDATA[\mathcal {R}]]></fr:tex> as two classes. If we recall standard supervised learning practice, given a sample <fr:tex
display="inline"><![CDATA[x]]></fr:tex>, we then want to find <fr:tex
display="block"><![CDATA[p(\mathcal {D} \mid  x) = 1 - p(\mathcal {R} \mid  X).]]></fr:tex> 
As an explicit example, we will use logistic regression. Namely, we will model <fr:tex
display="inline"><![CDATA[p(x) = p(\mathcal {D} \mid  x)]]></fr:tex> as <fr:tex
display="block"><![CDATA[p_{\theta }(x) = \frac {1}{1 + e^{-G_{\theta }(x)}}.]]></fr:tex> However, <fr:tex
display="inline"><![CDATA[p_{\theta }(x)]]></fr:tex> is estimating <fr:tex
display="inline"><![CDATA[p(\mathcal {D} \mid  x)]]></fr:tex>, where we care about <fr:tex
display="inline"><![CDATA[p(x \mid  \mathcal {D})]]></fr:tex>. To estimate the correct quantity, we need to leverage our knowledge of the noise distribution. Recall that if <fr:tex
display="inline"><![CDATA[p_{\theta }(x) = p(\mathcal {D} \mid  x)]]></fr:tex> then <fr:tex
display="inline"><![CDATA[G_{\theta }(x) = \log  \frac {p(x \mid  \mathcal {D})}{p(x \mid  \mathcal {R})}]]></fr:tex>. Since we generated the samples from <fr:tex
display="inline"><![CDATA[\mathcal {R}]]></fr:tex>, we have the explicit distribution i.e. <fr:tex
display="inline"><![CDATA[p(x \mid  \mathcal {R}) = p_{\mathcal {R}}(x)]]></fr:tex>. Therefore, we can restrict <fr:tex
display="inline"><![CDATA[G_{\theta }]]></fr:tex> to explicitly learn <fr:tex
display="inline"><![CDATA[p(x \mid  \mathcal {D})]]></fr:tex> by considering <fr:tex
display="block"><![CDATA[G_{\theta }(x) = \log  p_{\theta }(x \mid  \mathcal {D}) - \log  p_{\mathcal {R}}(x),]]></fr:tex> considering the cross entropy loss we get the <fr:link
type="external"
href="nce">NCE loss</fr:link></fr:p><fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>534</fr:anchor><fr:addr
type="user">kak-000E</fr:addr><fr:route>kak-000E.xml</fr:route><fr:title
text="NCE loss">NCE loss</fr:title><fr:taxon>Definition</fr:taxon><fr:date><fr:year>2024</fr:year><fr:month>11</fr:month><fr:day>4</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter><fr:p>The <fr:em><fr:link
type="external"
href="nce">NCE</fr:link></fr:em> loss aims to minimize the following objective <fr:tex
display="block"><![CDATA[\mathcal {L}_{N} = - \sum _{t} \log  \left [h(x_t; \theta )\right ] + \log \left [1 - h(y_t; \theta )\right ],]]></fr:tex> where <fr:tex
display="inline"><![CDATA[x_t]]></fr:tex> are samples from the data distribution and <fr:tex
display="inline"><![CDATA[y_t]]></fr:tex> are randomly generated samples and <fr:tex
display="block"><![CDATA[\begin {array}{r c l}{{h({\bf  u};\theta )}}&{{=}}&{{\frac {1}{1+\exp \left [-G({\bf  u};\theta )\right ]},}}\\ {{G({\bf  u};\theta )}}&{{=}}&{{\ln  p_{m}({\bf  u};\theta )-\ln  p_{n}({\bf  u}).}}\end {array}]]></fr:tex></fr:p></fr:mainmatter><fr:backmatter /></fr:tree><fr:p>In <fr:link
type="local"
href="gutmann2012.xml"
addr="gutmann2012"
title="Noise-contrastive Estimation">Noise-contrastive Estimation</fr:link>, they show under mild conditions that the estimator <fr:tex
display="inline"><![CDATA[p_{\theta }(x \mid  D) \to  p_{\mathcal {D}}(x)]]></fr:tex> in probability as the number of samples in the loss goes to infinity. Equivalently, the estimator is <fr:link
type="local"
href="kak-000F.xml"
addr="kak-000F"
title="Consistent estimator">consistent</fr:link>.</fr:p><fr:p><fr:strong>Time series:</fr:strong> Before we get to contrastive RL, it is a natural question to wonder how does this apply to temporal sequences? Concretely, we want to make predictions about the future given the current "context". However, we want to do so in an unsupervised way, meaning we are only given trajectories not a notion of what it means for a trajectory to be good. Naively, one can try to do this in a supervised manner. For a <fr:tex
display="inline"><![CDATA[k]]></fr:tex> step prediction, this would just be your model predicting what will happen in <fr:tex
display="inline"><![CDATA[k]]></fr:tex> steps then seeing if it matches what occured <fr:tex
display="inline"><![CDATA[k]]></fr:tex> steps in the future in the sample trajectory. However, if your sample space <fr:tex
display="inline"><![CDATA[\mathcal {X}]]></fr:tex> is very high-dimensional, modeling this relationship can require an exorbinant amount of trajectories.</fr:p><fr:p>Fast forwarding to contrastive RL, current work is primarily considered with a particular contrastive objective.</fr:p><fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>535</fr:anchor><fr:addr
type="user">kak-000B</fr:addr><fr:route>kak-000B.xml</fr:route><fr:title
text="InfoNCE">InfoNCE</fr:title><fr:taxon>Definition</fr:taxon><fr:date><fr:year>2024</fr:year><fr:month>11</fr:month><fr:day>4</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter><fr:p>The <fr:em><fr:link
type="local"
href="vandenOord2018.xml"
addr="vandenOord2018"
title="Contrastive Predictive Decoding">InfoNCE</fr:link></fr:em> loss aims to minimize the following information-theoretic objective <fr:tex
display="block"><![CDATA[\mathcal {L}_{N} = - \mathbb {E}_{\mathcal {X}} \left [\log  \frac {f_k(x_{t + k}, c_t)}{\sum _{x_j \in  \mathcal {X}} f_k(x_j, c_t)}\right ]]]></fr:tex></fr:p></fr:mainmatter><fr:backmatter /></fr:tree><fr:p>Now we need to unpack this very ominous loss. To start, what are <fr:tex
display="inline"><![CDATA[x_k]]></fr:tex> and <fr:tex
display="inline"><![CDATA[c_t]]></fr:tex>?</fr:p><fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>536</fr:anchor><fr:addr
type="user">kak-000C</fr:addr><fr:route>kak-000C.xml</fr:route><fr:title
text="Maximize Mutual info">Maximize Mutual info</fr:title><fr:taxon>Theorem</fr:taxon><fr:date><fr:year>2024</fr:year><fr:month>11</fr:month><fr:day>4</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter><fr:p><fr:tex
display="inline"><![CDATA[\mathcal {L}_N]]></fr:tex> from <fr:link
type="local"
href="vandenOord2018.xml"
addr="vandenOord2018"
title="Contrastive Predictive Decoding">Contrastive Predictive Decoding</fr:link> maximizes a lower bound on the <fr:link
type="local"
href="kak-000V.xml"
addr="kak-000V"
title="Mutual Information">Mutual Information</fr:link> between <fr:tex
display="inline"><![CDATA[x_{t + k}]]></fr:tex> and <fr:tex
display="inline"><![CDATA[c_t]]></fr:tex>.</fr:p>
   
   <fr:tree
toc="false"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>537</fr:anchor><fr:addr
type="machine">#316</fr:addr><fr:route>unstable-316.xml</fr:route><fr:taxon>Proof</fr:taxon><fr:date><fr:year>2024</fr:year><fr:month>11</fr:month><fr:day>4</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter>All we must do is plug <fr:tex
display="inline"><![CDATA[\frac {p(x \mid  c)}{p(x)}]]></fr:tex> back into the objective.
  <fr:tex
display="block"><![CDATA[\begin {align*}     \mathcal {L}_{\mathbb {N}}^{\text {opt}}&=-\,\mathbb {E}\log \left [\frac {\frac {p(x_{t+k}|c_{t})}{p(x_{t+k})}}{\frac {p(x_{t+k}|c_{t})}{p(x_{t+k})}+\sum _{x_{j}\in  X_{\text {neg}}}\frac {p(x_{j}|c_{t})}{p(x_{j})}}\right ] \\     &=\mathbb {E}\log \left [1+\frac {p(x_{t+k})}{p(x_{t+k}|c_{t})}\sum _{x_{j}\in  X_{\text {neg}}}\frac {p(x_{j}|c_{t})}{p(x_{j})}\right ] \\     &\approx \mathbb {E}\log \left [1+\frac {p(x_{t+k})}{p(x_{t+k}|c_{t})}(N-1)\,\mathbb {E}\,\frac {p(x_{j}|c_{t})}{p(x_{j})}\right ] \\     &=\mathbb {E}\log \left [1+\frac {p(x_{t+k})}{p(x_{t+k} \mid  c_t)}N\right ] \\     &\geq  \mathbb {E} \log  \left [\frac {p(x_{t + k})}{p(x_{t + k} \mid  c_t)}N \right ] \\     &= - I(x_{t + k}, c_t) + \log  N  \end {align*}   ]]></fr:tex>
</fr:mainmatter><fr:backmatter /></fr:tree>
 

</fr:mainmatter><fr:backmatter /></fr:tree></fr:mainmatter><fr:backmatter /></fr:tree></fr:mainmatter><fr:backmatter /></fr:tree></fr:mainmatter><fr:backmatter /></fr:tree><fr:tree
toc="false"
numbered="false"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:title
text="Related">Related</fr:title><fr:authors /></fr:frontmatter><fr:mainmatter><fr:tree
toc="true"
numbered="false"
show-heading="true"
show-metadata="true"
expanded="false"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>1412</fr:anchor><fr:addr
type="user">kak-000F</fr:addr><fr:route>kak-000F.xml</fr:route><fr:title
text="Consistent estimator">Consistent estimator</fr:title><fr:taxon>Definition</fr:taxon><fr:date><fr:year>2024</fr:year><fr:month>11</fr:month><fr:day>4</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter><fr:p>Formally speaking, an estimator <fr:tex
display="inline"><![CDATA[T_{n}]]></fr:tex> of parameter <fr:tex
display="inline"><![CDATA[\theta ]]></fr:tex> is said to be <fr:em>weakly consistent</fr:em>. If it converges in probabilty to the true value of the parameter i.er

<fr:tex
display="block"><![CDATA[\lim \limits _{n\rightarrow \infty }T_{n}=\theta . \quad  \text { i.e. for all t>0 } \quad  \lim \limits _{n\rightarrow \infty }\Pr \left (\left |T_{n}-\theta \right |>c\right )=0.]]></fr:tex></fr:p></fr:mainmatter><fr:backmatter /></fr:tree></fr:mainmatter><fr:backmatter /></fr:tree></fr:backmatter></fr:tree>